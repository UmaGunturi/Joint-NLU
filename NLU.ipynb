{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKeTCvVfOgXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "945bef17-7232-4b43-d4de-ebec1b77e1b2"
      },
      "source": [
        "!pip install tensorflow_gpu==2.0.0-alpha0\n",
        "\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0-alpha0) (0.1.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow_gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow_gpu==2.0.0-alpha0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow_gpu==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_gpu==2.0.0-alpha0) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6MWvRuw5qBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow_hub\n",
        "#import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q_AmIPpZUNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfBoYytHQGgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "a3f48abb-ef37-4c61-bffd-4c2f062aee90"
      },
      "source": [
        "!unzip src\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  src.zip\n",
            "  inflating: src/.ipynb_checkpoints/utils-checkpoint.py  \n",
            "replace src/__pycache__/utils.cpython-36.pyc? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: src/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: src/data/atis/test/label  \n",
            "  inflating: src/data/atis/test/seq.in  \n",
            "  inflating: src/data/atis/test/seq.out  \n",
            "  inflating: src/data/atis/train/label  \n",
            "  inflating: src/data/atis/train/seq.in  \n",
            "  inflating: src/data/atis/train/seq.out  \n",
            "  inflating: src/data/atis/valid/label  \n",
            "  inflating: src/data/atis/valid/seq.in  \n",
            "  inflating: src/data/atis/valid/seq.out  \n",
            "  inflating: src/data/snips/test/label  \n",
            "  inflating: src/data/snips/test/seq.in  \n",
            "  inflating: src/data/snips/test/seq.out  \n",
            "  inflating: src/data/snips/train/label  \n",
            "  inflating: src/data/snips/train/seq.in  \n",
            "  inflating: src/data/snips/train/seq.out  \n",
            "  inflating: src/data/snips/valid/label  \n",
            "  inflating: src/data/snips/valid/seq.in  \n",
            "  inflating: src/data/snips/valid/seq.out  \n",
            " extracting: src/model/.gitignore    \n",
            "  inflating: src/utils.py            \n",
            " extracting: src/vocab/in_vocab      \n",
            "  inflating: src/vocab/intent_vocab  \n",
            "  inflating: src/vocab/slot_vocab    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKH1Rn9IQggx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/src')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRvJ2KpDRKHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "#from tensorflow.python.ops import rnn_cell_impl\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from utils import createVocabulary\n",
        "from utils import loadVocabulary\n",
        "from utils import computeF1Score\n",
        "from utils import DataProcessor\n",
        "\n",
        "parser = argparse.ArgumentParser(allow_abbrev=False)\n",
        "\n",
        "#Network\n",
        "parser.add_argument(\"--num_units\", type=int, default=128, help=\"Network size.\", dest='layer_size')\n",
        "parser.add_argument(\"--model_type\", type=str, default='full', help=\"\"\"full(default) | intent_only\n",
        "                                                                    full: full attention model\n",
        "                                                                    intent_only: intent attention model\"\"\")\n",
        "\n",
        "#Training Environment\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size.\")\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=20, help=\"Max epochs to train.\")\n",
        "parser.add_argument(\"--no_early_stop\", action='store_false',dest='early_stop', help=\"Disable early stop, which is based on sentence level accuracy.\")\n",
        "parser.add_argument(\"--patience\", type=int, default=5, help=\"Patience to wait before stop.\")\n",
        "\n",
        "#Model and Vocab\n",
        "parser.add_argument(\"--dataset\", type=str, default=None, help=\"\"\"Type 'atis' or 'snips' to use dataset provided by us or enter what ever you named your own dataset.\n",
        "                Note, if you don't want to use this part, enter --dataset=''. It can not be None\"\"\")\n",
        "parser.add_argument(\"--model_path\", type=str, default='./src/model', help=\"Path to save model.\")\n",
        "parser.add_argument(\"--vocab_path\", type=str, default='./src/vocab', help=\"Path to vocabulary files.\")\n",
        "\n",
        "#Data\n",
        "parser.add_argument(\"--train_data_path\", type=str, default='train', help=\"Path to training data files.\")\n",
        "parser.add_argument(\"--test_data_path\", type=str, default='test', help=\"Path to testing data files.\")\n",
        "parser.add_argument(\"--valid_data_path\", type=str, default='valid', help=\"Path to validation data files.\")\n",
        "parser.add_argument(\"--input_file\", type=str, default='seq.in', help=\"Input file name.\")\n",
        "parser.add_argument(\"--slot_file\", type=str, default='seq.out', help=\"Slot file name.\")\n",
        "parser.add_argument(\"--intent_file\", type=str, default='label', help=\"Intent file name.\")\n",
        "\n",
        "arg=parser.parse_args([\"--dataset\",\"snips\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJw4ZYsyRpJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "30997e90-b85d-4fbe-a34c-e2bee47fe71e"
      },
      "source": [
        "#Print arguments\n",
        "for k,v in sorted(vars(arg).items()):\n",
        "    print(k,'=',v)\n",
        "print()\n",
        "\n",
        "if arg.model_type == 'full':\n",
        "    add_final_state_to_intent = True\n",
        "    remove_slot_attn = False\n",
        "elif arg.model_type == 'intent_only':\n",
        "    add_final_state_to_intent = True\n",
        "    remove_slot_attn = True\n",
        "else:\n",
        "    print('unknown model type!')\n",
        "    exit(1)\n",
        "\n",
        "#full path to data will be: ./data + dataset + train/test/valid\n",
        "if arg.dataset == None:\n",
        "    print('name of dataset can not be None')\n",
        "    exit(1)\n",
        "elif arg.dataset == 'snips':\n",
        "    print('use snips dataset')\n",
        "elif arg.dataset == 'atis':\n",
        "    print('use atis dataset')\n",
        "else:\n",
        "    print('use own dataset: ',arg.dataset)\n",
        "full_train_path = os.path.join('./src/data',arg.dataset,arg.train_data_path)\n",
        "full_test_path = os.path.join('./src/data',arg.dataset,arg.test_data_path)\n",
        "full_valid_path = os.path.join('./src/data',arg.dataset,arg.valid_data_path)\n",
        "\n",
        "createVocabulary(os.path.join(full_train_path, arg.input_file), os.path.join(arg.vocab_path, 'in_vocab'))\n",
        "createVocabulary(os.path.join(full_train_path, arg.slot_file), os.path.join(arg.vocab_path, 'slot_vocab'))\n",
        "createVocabulary(os.path.join(full_train_path, arg.intent_file), os.path.join(arg.vocab_path, 'intent_vocab'))\n",
        "\n",
        "in_vocab = loadVocabulary(os.path.join(arg.vocab_path, 'in_vocab'))\n",
        "slot_vocab = loadVocabulary(os.path.join(arg.vocab_path, 'slot_vocab'))\n",
        "intent_vocab = loadVocabulary(os.path.join(arg.vocab_path, 'intent_vocab'))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size = 64\n",
            "dataset = snips\n",
            "early_stop = True\n",
            "input_file = seq.in\n",
            "intent_file = label\n",
            "layer_size = 128\n",
            "max_epochs = 20\n",
            "model_path = ./src/model\n",
            "model_type = full\n",
            "patience = 5\n",
            "slot_file = seq.out\n",
            "test_data_path = test\n",
            "train_data_path = train\n",
            "valid_data_path = valid\n",
            "vocab_path = ./src/vocab\n",
            "\n",
            "use snips dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxCeThXUK1bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NOT USING CURRENTLY\n",
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, hidden_size)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Bbh5PQWFbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "class CustomDropout(layers.Layer):\n",
        "  def __init__(self, rate, **kwargs):\n",
        "    super(CustomDropout, self).__init__(**kwargs)\n",
        "    self.rate = rate\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    if training:\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "    return inputs\n",
        "  \n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, input_size, slot_size, intent_size, layer_size = 128):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(input_size, layer_size)\n",
        "    self.bilstm = tf.keras.layers.Bidirectional(CuDNNLSTM(layer_size, return_sequences=True,return_state=True))\n",
        "    self.dropout = CustomDropout(0.5)\n",
        "    self.intent_out = tf.keras.layers.Dense(intent_size, activation=None)\n",
        "    self.slot_out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(slot_size, activation=None))\n",
        "  \n",
        "  @tf.function  \n",
        "  def call(self, inputs, sequence_length, isTraining=True):\n",
        "    x = self.embedding(inputs)\n",
        "    state_outputs, forward_h, forward_c, backward_h, backward_c = self.bilstm(x)\n",
        "    \n",
        "    state_outputs = self.dropout(state_outputs, isTraining)\n",
        "    forward_h = self.dropout(forward_h, isTraining)\n",
        "    backward_h = self.dropout(backward_h, isTraining)\n",
        "   \n",
        "    final_state = tf.keras.layers.concatenate([forward_h,backward_h])\n",
        "    intent = self.intent_out(final_state)\n",
        "    slots = self.slot_out(state_outputs)\n",
        "    outputs = [slots, intent]\n",
        "    return outputs\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4WTGWQX4AH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = MyModel(len(in_vocab['vocab']), len(slot_vocab['vocab']), len(intent_vocab['vocab']), layer_size=arg.layer_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeOx6foM60O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"import time\n",
        "t = time.perf_counter() #time.process_time()\n",
        "slots, intent = model(in_data, length)\n",
        "elapsed = time.perf_counter() - t\n",
        "print(elapsed)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geNgBiAPXffN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def valid(in_path, slot_path, intent_path):\n",
        "    data_processor_valid = DataProcessor(in_path, slot_path, intent_path, in_vocab, slot_vocab, intent_vocab)\n",
        "    pred_intents = []\n",
        "    correct_intents = []\n",
        "    slot_outputs = []\n",
        "    correct_slots = []\n",
        "    input_words = []\n",
        "\n",
        "    #used to gate\n",
        "    #gate_seq = []\n",
        "    while True:\n",
        "        in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq = data_processor_valid.get_batch(arg.batch_size)\n",
        "        #feed_dict = {input_data.name: in_data, sequence_length.name: length}\n",
        "        #ret = sess.run(inference_outputs, feed_dict)\n",
        "        slots, intent = model(in_data, length, isTraining = False)\n",
        "        for i in np.array(intent):\n",
        "            pred_intents.append(np.argmax(i))\n",
        "        for i in intents:\n",
        "            correct_intents.append(i)\n",
        "\n",
        "        pred_slots = slots\n",
        "        for p, t, i, l in zip(pred_slots, slot_data, in_data, length):\n",
        "            p = np.argmax(p, 1)\n",
        "            tmp_pred = []\n",
        "            tmp_correct = []\n",
        "            tmp_input = []\n",
        "            for j in range(l):\n",
        "                tmp_pred.append(slot_vocab['rev'][p[j]])\n",
        "                tmp_correct.append(slot_vocab['rev'][t[j]])\n",
        "                tmp_input.append(in_vocab['rev'][i[j]])\n",
        "\n",
        "            slot_outputs.append(tmp_pred)\n",
        "            correct_slots.append(tmp_correct)\n",
        "            input_words.append(tmp_input)\n",
        "\n",
        "        if data_processor_valid.end == 1:\n",
        "            break\n",
        "\n",
        "    pred_intents = np.array(pred_intents)\n",
        "    correct_intents = np.array(correct_intents)\n",
        "    accuracy = (pred_intents==correct_intents)\n",
        "    semantic_error = accuracy\n",
        "    accuracy = accuracy.astype(float)\n",
        "    accuracy = np.mean(accuracy)*100.0\n",
        "\n",
        "    index = 0\n",
        "    for t, p in zip(correct_slots, slot_outputs):\n",
        "        # Process Semantic Error\n",
        "        if len(t) != len(p):\n",
        "            raise ValueError('Error!!')\n",
        "\n",
        "        for j in range(len(t)):\n",
        "            if p[j] != t[j]:\n",
        "                semantic_error[index] = False\n",
        "                break\n",
        "        index += 1\n",
        "    semantic_error = semantic_error.astype(float)\n",
        "    semantic_error = np.mean(semantic_error)*100.0\n",
        "\n",
        "    f1, precision, recall = computeF1Score(correct_slots, slot_outputs)\n",
        "    print('slot f1: ' + str(f1) + '\\tintent accuracy: ' + str(accuracy) + '\\tsemantic_error: ' + str(semantic_error))\n",
        "    #print('intent accuracy: ' + str(accuracy))\n",
        "    #print('semantic error(intent, slots are all correct): ' + str(semantic_error))\n",
        "\n",
        "    data_processor_valid.close()\n",
        "    return f1,accuracy,semantic_error,pred_intents,correct_intents,slot_outputs,correct_slots,input_words#,gate_seq\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrfg5-eOY9Do",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3366
        },
        "outputId": "f5c0b4ab-117d-467e-8347-a858b8ae303a"
      },
      "source": [
        "#training\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(-1), optimizer=opt, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, arg.model_path + \"/\" + arg.dataset + '/tf_ckpts', max_to_keep=3)\n",
        "data_processor = None\n",
        "valid_err = 0\n",
        "no_improve= 0\n",
        "save_path = os.path.join(arg.model_path , str(arg.dataset) + \"/\")\n",
        "for epoch in range(50):\n",
        "    while True:\n",
        "        if data_processor == None:\n",
        "            i_loss = 0\n",
        "            s_loss = 0\n",
        "            batches = 0\n",
        "            data_processor = DataProcessor(os.path.join(full_train_path, arg.input_file), os.path.join(full_train_path, arg.slot_file), os.path.join(full_train_path, arg.intent_file), in_vocab, slot_vocab, intent_vocab)\n",
        "        in_data, slot_labels, slot_weights, length, intent_labels,in_seq,_,_ = data_processor.get_batch(arg.batch_size)\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "          slots, intent = model(in_data, length, isTraining = True)\n",
        "          intent_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=intent_labels, logits=intent)  \n",
        "          #slot_loss\n",
        "          slots_out = tf.reshape(slots, [-1,len(slot_vocab['vocab'])])\n",
        "          slots_shape = tf.shape(slot_labels)\n",
        "          slot_reshape = tf.reshape(slot_labels, [-1])\n",
        "          crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=slot_reshape, logits=slots_out)\n",
        "          crossent = tf.reshape(crossent, slots_shape)\n",
        "          slot_loss = tf.reduce_sum(crossent*slot_weights, 1)\n",
        "          total_size = tf.reduce_sum(slot_weights, 1)\n",
        "          total_size += 1e-12\n",
        "          slot_loss = slot_loss / total_size\n",
        "          \n",
        "          total_loss = intent_loss + slot_loss\n",
        "        \n",
        "        grads = tape.gradient(total_loss, model.trainable_weights)\n",
        "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
        "        s_loss = s_loss + tf.reduce_sum(slot_loss)/tf.cast(arg.batch_size, tf.float32)\n",
        "        i_loss = i_loss +  tf.reduce_sum(intent_loss)/tf.cast(arg.batch_size, tf.float32)\n",
        "        batches = batches + 1\n",
        "        if data_processor.end == 1:\n",
        "            data_processor.close()\n",
        "            data_processor = None\n",
        "            break\n",
        "            \n",
        "    #print(\"Training Epoch: \" ,epoch,\" Slot Loss: \",s_loss/batches, \" Intent_Loss: \", i_loss/batches)\n",
        "    print(\"EPOCH: \", epoch, \" *******************************************************************\")\n",
        "    print('Train:', end=\"\\t\")\n",
        "    _ = valid(os.path.join(full_train_path, arg.input_file), os.path.join(full_train_path, arg.slot_file), os.path.join(full_train_path, arg.intent_file))\n",
        "    \n",
        "    print('Valid:', end=\"\\t\")\n",
        "    epoch_valid_slot, epoch_valid_intent, epoch_valid_err,valid_pred_intent,valid_correct_intent,valid_pred_slot,valid_correct_slot,valid_words = valid(os.path.join(full_valid_path, arg.input_file), os.path.join(full_valid_path, arg.slot_file), os.path.join(full_valid_path, arg.intent_file))\n",
        "\n",
        "    print('Test:', end=\"\\t\")\n",
        "    epoch_test_slot, epoch_test_intent, epoch_test_err,test_pred_intent,test_correct_intent,test_pred_slot,test_correct_slot,test_words = valid(os.path.join(full_test_path, arg.input_file), os.path.join(full_test_path, arg.slot_file), os.path.join(full_test_path, arg.intent_file))\n",
        "    \n",
        "    ckpt.step.assign_add(1)\n",
        "    if epoch_valid_err <= valid_err:\n",
        "        no_improve += 1\n",
        "    else:\n",
        "        valid_err = epoch_valid_err\n",
        "        no_improve = 0\n",
        "        print(\"Saving\", str(ckpt.step), \"with valid accuracy:\", valid_err   )\n",
        "        save_path = manager.save()\n",
        "\n",
        "    if arg.early_stop == True:\n",
        "        if no_improve > arg.patience:\n",
        "            print(\"EARLY BREAK\")\n",
        "            break\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH:  0  *******************************************************************\n",
            "Train:\tslot f1: 45.59998847976039\tintent accuracy: 99.16692143075511\tsemantic_error: 14.162335677162947\n",
            "Valid:\tslot f1: 43.66120218579235\tintent accuracy: 97.85714285714285\tsemantic_error: 13.285714285714286\n",
            "Test:\tslot f1: 42.33815897295821\tintent accuracy: 96.71428571428572\tsemantic_error: 13.571428571428571\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> with valid accuracy: 13.285714285714286\n",
            "EPOCH:  1  *******************************************************************\n",
            "Train:\tslot f1: 67.21357930233216\tintent accuracy: 99.3656374197493\tsemantic_error: 39.4145521247325\n",
            "Valid:\tslot f1: 61.47278548559231\tintent accuracy: 97.71428571428571\tsemantic_error: 31.142857142857146\n",
            "Test:\tslot f1: 61.69419286094832\tintent accuracy: 96.42857142857143\tsemantic_error: 32.42857142857143\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1> with valid accuracy: 31.142857142857146\n",
            "EPOCH:  2  *******************************************************************\n",
            "Train:\tslot f1: 79.61627277133164\tintent accuracy: 99.77071232039133\tsemantic_error: 57.95628248242127\n",
            "Valid:\tslot f1: 72.24740069314849\tintent accuracy: 97.85714285714285\tsemantic_error: 45.714285714285715\n",
            "Test:\tslot f1: 70.58195408435665\tintent accuracy: 96.85714285714285\tsemantic_error: 42.57142857142857\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2> with valid accuracy: 45.714285714285715\n",
            "EPOCH:  3  *******************************************************************\n",
            "Train:\tslot f1: 84.98607162344561\tintent accuracy: 99.87007031488841\tsemantic_error: 67.31886273310914\n",
            "Valid:\tslot f1: 76.52733118971061\tintent accuracy: 98.42857142857143\tsemantic_error: 53.0\n",
            "Test:\tslot f1: 74.98660953401179\tintent accuracy: 96.14285714285714\tsemantic_error: 49.57142857142857\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3> with valid accuracy: 53.0\n",
            "EPOCH:  4  *******************************************************************\n",
            "Train:\tslot f1: 88.54055611583347\tintent accuracy: 99.9006420055029\tsemantic_error: 74.34270865178844\n",
            "Valid:\tslot f1: 79.96781979082864\tintent accuracy: 98.14285714285714\tsemantic_error: 59.0\n",
            "Test:\tslot f1: 76.34322373696872\tintent accuracy: 96.57142857142857\tsemantic_error: 51.857142857142854\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=4> with valid accuracy: 59.0\n",
            "EPOCH:  5  *******************************************************************\n",
            "Train:\tslot f1: 90.70545791738508\tintent accuracy: 99.93885661877103\tsemantic_error: 78.80617548150413\n",
            "Valid:\tslot f1: 81.097069104598\tintent accuracy: 98.57142857142858\tsemantic_error: 61.42857142857143\n",
            "Test:\tslot f1: 78.60402684563758\tintent accuracy: 97.42857142857143\tsemantic_error: 57.57142857142858\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5> with valid accuracy: 61.42857142857143\n",
            "EPOCH:  6  *******************************************************************\n",
            "Train:\tslot f1: 92.41876207492629\tintent accuracy: 99.99235707734637\tsemantic_error: 82.3601345154387\n",
            "Valid:\tslot f1: 82.21684153887543\tintent accuracy: 97.85714285714285\tsemantic_error: 63.714285714285715\n",
            "Test:\tslot f1: 80.1403130059363\tintent accuracy: 96.85714285714285\tsemantic_error: 59.71428571428572\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=6> with valid accuracy: 63.714285714285715\n",
            "EPOCH:  7  *******************************************************************\n",
            "Train:\tslot f1: 93.65637997731307\tintent accuracy: 99.96178538673189\tsemantic_error: 85.40201773158056\n",
            "Valid:\tslot f1: 83.00565580393213\tintent accuracy: 98.28571428571429\tsemantic_error: 66.28571428571428\n",
            "Test:\tslot f1: 81.35775862068965\tintent accuracy: 97.28571428571429\tsemantic_error: 62.142857142857146\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7> with valid accuracy: 66.28571428571428\n",
            "EPOCH:  8  *******************************************************************\n",
            "Train:\tslot f1: 94.46281593706753\tintent accuracy: 99.97707123203912\tsemantic_error: 87.02231733414858\n",
            "Valid:\tslot f1: 83.6038961038961\tintent accuracy: 98.71428571428571\tsemantic_error: 67.0\n",
            "Test:\tslot f1: 81.66351606805293\tintent accuracy: 97.14285714285714\tsemantic_error: 63.42857142857142\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=8> with valid accuracy: 67.0\n",
            "EPOCH:  9  *******************************************************************\n",
            "Train:\tslot f1: 95.09125419769309\tintent accuracy: 100.0\tsemantic_error: 88.46682971568328\n",
            "Valid:\tslot f1: 83.78890392422193\tintent accuracy: 98.71428571428571\tsemantic_error: 68.28571428571428\n",
            "Test:\tslot f1: 81.177423710505\tintent accuracy: 97.14285714285714\tsemantic_error: 63.714285714285715\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=9> with valid accuracy: 68.28571428571428\n",
            "EPOCH:  10  *******************************************************************\n",
            "Train:\tslot f1: 95.60875912408758\tintent accuracy: 99.93885661877103\tsemantic_error: 89.66676857230205\n",
            "Valid:\tslot f1: 83.75607123583377\tintent accuracy: 98.85714285714286\tsemantic_error: 67.42857142857143\n",
            "Test:\tslot f1: 81.61725067385446\tintent accuracy: 97.57142857142857\tsemantic_error: 63.57142857142857\n",
            "EPOCH:  11  *******************************************************************\n",
            "Train:\tslot f1: 96.19649492378359\tintent accuracy: 99.99235707734637\tsemantic_error: 91.10363803118312\n",
            "Valid:\tslot f1: 83.7486457204767\tintent accuracy: 98.57142857142858\tsemantic_error: 67.57142857142857\n",
            "Test:\tslot f1: 81.71984856679285\tintent accuracy: 96.57142857142857\tsemantic_error: 63.857142857142854\n",
            "EPOCH:  12  *******************************************************************\n",
            "Train:\tslot f1: 96.72596407045467\tintent accuracy: 99.97707123203912\tsemantic_error: 92.3035768878019\n",
            "Valid:\tslot f1: 83.99460188933874\tintent accuracy: 98.42857142857143\tsemantic_error: 67.28571428571428\n",
            "Test:\tslot f1: 82.68971104509858\tintent accuracy: 97.14285714285714\tsemantic_error: 64.57142857142857\n",
            "EPOCH:  13  *******************************************************************\n",
            "Train:\tslot f1: 97.29935559461042\tintent accuracy: 100.0\tsemantic_error: 93.4805869764598\n",
            "Valid:\tslot f1: 84.62371413102328\tintent accuracy: 98.42857142857143\tsemantic_error: 69.0\n",
            "Test:\tslot f1: 82.18808946375641\tintent accuracy: 96.57142857142857\tsemantic_error: 64.14285714285714\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=13> with valid accuracy: 69.0\n",
            "EPOCH:  14  *******************************************************************\n",
            "Train:\tslot f1: 97.51484495271609\tintent accuracy: 100.0\tsemantic_error: 94.03852033017426\n",
            "Valid:\tslot f1: 85.0257243433523\tintent accuracy: 98.42857142857143\tsemantic_error: 69.42857142857143\n",
            "Test:\tslot f1: 82.29897463572584\tintent accuracy: 97.14285714285714\tsemantic_error: 65.57142857142857\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=14> with valid accuracy: 69.42857142857143\n",
            "EPOCH:  15  *******************************************************************\n",
            "Train:\tslot f1: 98.08228015130635\tintent accuracy: 100.0\tsemantic_error: 95.22317334148579\n",
            "Valid:\tslot f1: 85.51313295423775\tintent accuracy: 98.57142857142858\tsemantic_error: 69.71428571428572\n",
            "Test:\tslot f1: 82.46753246753248\tintent accuracy: 97.14285714285714\tsemantic_error: 66.14285714285715\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=15> with valid accuracy: 69.71428571428572\n",
            "EPOCH:  16  *******************************************************************\n",
            "Train:\tslot f1: 98.34338454314684\tintent accuracy: 100.0\tsemantic_error: 95.75053500458576\n",
            "Valid:\tslot f1: 85.96918085969182\tintent accuracy: 98.42857142857143\tsemantic_error: 71.14285714285714\n",
            "Test:\tslot f1: 82.83100107642628\tintent accuracy: 96.71428571428572\tsemantic_error: 66.42857142857143\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=16> with valid accuracy: 71.14285714285714\n",
            "EPOCH:  17  *******************************************************************\n",
            "Train:\tslot f1: 98.58220565356503\tintent accuracy: 100.0\tsemantic_error: 96.39254050749007\n",
            "Valid:\tslot f1: 86.51715752499324\tintent accuracy: 98.71428571428571\tsemantic_error: 71.14285714285714\n",
            "Test:\tslot f1: 82.67674042093903\tintent accuracy: 97.0\tsemantic_error: 66.0\n",
            "EPOCH:  18  *******************************************************************\n",
            "Train:\tslot f1: 98.69118791956167\tintent accuracy: 100.0\tsemantic_error: 96.69825741363496\n",
            "Valid:\tslot f1: 85.91587516960651\tintent accuracy: 98.57142857142858\tsemantic_error: 71.57142857142857\n",
            "Test:\tslot f1: 82.40366478038264\tintent accuracy: 96.42857142857143\tsemantic_error: 65.28571428571428\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=18> with valid accuracy: 71.57142857142857\n",
            "EPOCH:  19  *******************************************************************\n",
            "Train:\tslot f1: 98.72256603995474\tintent accuracy: 100.0\tsemantic_error: 96.66768572302048\n",
            "Valid:\tslot f1: 85.54380254949822\tintent accuracy: 98.42857142857143\tsemantic_error: 70.57142857142857\n",
            "Test:\tslot f1: 82.2065981611682\tintent accuracy: 97.28571428571429\tsemantic_error: 65.0\n",
            "EPOCH:  20  *******************************************************************\n",
            "Train:\tslot f1: 98.80063495796342\tintent accuracy: 100.0\tsemantic_error: 96.99633139712626\n",
            "Valid:\tslot f1: 86.17310832879696\tintent accuracy: 98.57142857142858\tsemantic_error: 71.85714285714285\n",
            "Test:\tslot f1: 82.07343412526998\tintent accuracy: 97.28571428571429\tsemantic_error: 64.71428571428571\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=20> with valid accuracy: 71.85714285714285\n",
            "EPOCH:  21  *******************************************************************\n",
            "Train:\tslot f1: 98.48475949961826\tintent accuracy: 99.96178538673189\tsemantic_error: 96.27789666768572\n",
            "Valid:\tslot f1: 85.18016797615822\tintent accuracy: 98.42857142857143\tsemantic_error: 70.85714285714285\n",
            "Test:\tslot f1: 82.72138228941685\tintent accuracy: 97.14285714285714\tsemantic_error: 66.57142857142857\n",
            "EPOCH:  22  *******************************************************************\n",
            "Train:\tslot f1: 98.26784588081723\tintent accuracy: 99.94649954142464\tsemantic_error: 95.77346377254662\n",
            "Valid:\tslot f1: 84.82070638986251\tintent accuracy: 98.57142857142858\tsemantic_error: 69.85714285714286\n",
            "Test:\tslot f1: 82.508073196986\tintent accuracy: 97.42857142857143\tsemantic_error: 65.42857142857143\n",
            "EPOCH:  23  *******************************************************************\n",
            "Train:\tslot f1: 98.79857826866021\tintent accuracy: 99.99235707734637\tsemantic_error: 97.06511770100886\n",
            "Valid:\tslot f1: 85.21221951878886\tintent accuracy: 98.42857142857143\tsemantic_error: 69.71428571428572\n",
            "Test:\tslot f1: 82.736331807164\tintent accuracy: 97.0\tsemantic_error: 65.71428571428571\n",
            "EPOCH:  24  *******************************************************************\n",
            "Train:\tslot f1: 99.13866596113708\tintent accuracy: 100.0\tsemantic_error: 97.69183735860592\n",
            "Valid:\tslot f1: 86.55986967146349\tintent accuracy: 98.57142857142858\tsemantic_error: 71.0\n",
            "Test:\tslot f1: 83.32884460005387\tintent accuracy: 97.28571428571429\tsemantic_error: 66.85714285714286\n",
            "EPOCH:  25  *******************************************************************\n",
            "Train:\tslot f1: 99.23556391861696\tintent accuracy: 100.0\tsemantic_error: 97.95933965148272\n",
            "Valid:\tslot f1: 86.92349430276722\tintent accuracy: 98.71428571428571\tsemantic_error: 72.14285714285714\n",
            "Test:\tslot f1: 83.50404312668464\tintent accuracy: 97.42857142857143\tsemantic_error: 67.14285714285714\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=25> with valid accuracy: 72.14285714285714\n",
            "EPOCH:  26  *******************************************************************\n",
            "Train:\tslot f1: 99.30752605966155\tintent accuracy: 100.0\tsemantic_error: 98.1504127178233\n",
            "Valid:\tslot f1: 86.1413043478261\tintent accuracy: 98.71428571428571\tsemantic_error: 71.14285714285714\n",
            "Test:\tslot f1: 83.41871124292261\tintent accuracy: 97.28571428571429\tsemantic_error: 66.71428571428571\n",
            "EPOCH:  27  *******************************************************************\n",
            "Train:\tslot f1: 99.37347413007029\tintent accuracy: 99.99235707734637\tsemantic_error: 98.27269948028126\n",
            "Valid:\tslot f1: 86.3882863340564\tintent accuracy: 98.57142857142858\tsemantic_error: 71.14285714285714\n",
            "Test:\tslot f1: 83.0361966504592\tintent accuracy: 97.14285714285714\tsemantic_error: 66.57142857142857\n",
            "EPOCH:  28  *******************************************************************\n",
            "Train:\tslot f1: 99.32190924468632\tintent accuracy: 99.77071232039133\tsemantic_error: 97.90583919290737\n",
            "Valid:\tslot f1: 86.12622415669206\tintent accuracy: 97.85714285714285\tsemantic_error: 70.71428571428572\n",
            "Test:\tslot f1: 83.62652232746954\tintent accuracy: 96.28571428571429\tsemantic_error: 66.28571428571428\n",
            "EPOCH:  29  *******************************************************************\n",
            "Train:\tslot f1: 99.34277270521812\tintent accuracy: 99.97707123203912\tsemantic_error: 98.1504127178233\n",
            "Valid:\tslot f1: 86.80781758957654\tintent accuracy: 99.14285714285714\tsemantic_error: 71.42857142857143\n",
            "Test:\tslot f1: 83.45945945945947\tintent accuracy: 97.0\tsemantic_error: 66.14285714285715\n",
            "EPOCH:  30  *******************************************************************\n",
            "Train:\tslot f1: 99.45421110702465\tintent accuracy: 100.0\tsemantic_error: 98.46377254662183\n",
            "Valid:\tslot f1: 86.70111503943433\tintent accuracy: 98.85714285714286\tsemantic_error: 71.71428571428572\n",
            "Test:\tslot f1: 83.6038961038961\tintent accuracy: 96.85714285714285\tsemantic_error: 67.14285714285714\n",
            "EPOCH:  31  *******************************************************************\n",
            "Train:\tslot f1: 99.53949594668157\tintent accuracy: 100.0\tsemantic_error: 98.73891776215224\n",
            "Valid:\tslot f1: 87.21845318860244\tintent accuracy: 98.57142857142858\tsemantic_error: 72.71428571428571\n",
            "Test:\tslot f1: 83.66189576019443\tintent accuracy: 96.42857142857143\tsemantic_error: 67.57142857142857\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=31> with valid accuracy: 72.71428571428571\n",
            "EPOCH:  32  *******************************************************************\n",
            "Train:\tslot f1: 99.57777352772426\tintent accuracy: 100.0\tsemantic_error: 98.82298991134209\n",
            "Valid:\tslot f1: 86.96360673546985\tintent accuracy: 99.0\tsemantic_error: 72.0\n",
            "Test:\tslot f1: 83.19870759289176\tintent accuracy: 96.71428571428572\tsemantic_error: 66.28571428571428\n",
            "EPOCH:  33  *******************************************************************\n",
            "Train:\tslot f1: 99.61146759286514\tintent accuracy: 100.0\tsemantic_error: 98.91470498318557\n",
            "Valid:\tslot f1: 86.2883518870486\tintent accuracy: 98.71428571428571\tsemantic_error: 71.42857142857143\n",
            "Test:\tslot f1: 83.48202216815355\tintent accuracy: 96.42857142857143\tsemantic_error: 67.57142857142857\n",
            "EPOCH:  34  *******************************************************************\n",
            "Train:\tslot f1: 99.69391959503207\tintent accuracy: 100.0\tsemantic_error: 99.08284928156526\n",
            "Valid:\tslot f1: 86.47619047619048\tintent accuracy: 98.85714285714286\tsemantic_error: 71.0\n",
            "Test:\tslot f1: 83.37845154304277\tintent accuracy: 96.57142857142857\tsemantic_error: 66.85714285714286\n",
            "EPOCH:  35  *******************************************************************\n",
            "Train:\tslot f1: 99.67772790817452\tintent accuracy: 100.0\tsemantic_error: 99.10577804952614\n",
            "Valid:\tslot f1: 86.93289866884\tintent accuracy: 98.85714285714286\tsemantic_error: 72.71428571428571\n",
            "Test:\tslot f1: 83.2747905971359\tintent accuracy: 96.71428571428572\tsemantic_error: 67.14285714285714\n",
            "EPOCH:  36  *******************************************************************\n",
            "Train:\tslot f1: 99.74383888349085\tintent accuracy: 100.0\tsemantic_error: 99.1974931213696\n",
            "Valid:\tslot f1: 87.28165938864629\tintent accuracy: 99.0\tsemantic_error: 72.85714285714285\n",
            "Test:\tslot f1: 83.7486457204767\tintent accuracy: 96.85714285714285\tsemantic_error: 67.57142857142857\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=36> with valid accuracy: 72.85714285714285\n",
            "EPOCH:  37  *******************************************************************\n",
            "Train:\tslot f1: 99.72769690457618\tintent accuracy: 100.0\tsemantic_error: 99.16692143075511\n",
            "Valid:\tslot f1: 87.57814623539007\tintent accuracy: 99.0\tsemantic_error: 73.57142857142858\n",
            "Test:\tslot f1: 83.10010764262647\tintent accuracy: 97.42857142857143\tsemantic_error: 66.0\n",
            "Saving <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=37> with valid accuracy: 73.57142857142858\n",
            "EPOCH:  38  *******************************************************************\n",
            "Train:\tslot f1: 99.73801183362279\tintent accuracy: 100.0\tsemantic_error: 99.23570773463773\n",
            "Valid:\tslot f1: 86.89730318714247\tintent accuracy: 98.71428571428571\tsemantic_error: 71.85714285714285\n",
            "Test:\tslot f1: 83.62652232746954\tintent accuracy: 97.0\tsemantic_error: 67.42857142857143\n",
            "EPOCH:  39  *******************************************************************\n",
            "Train:\tslot f1: 99.82628665645979\tintent accuracy: 99.99235707734637\tsemantic_error: 99.48028125955365\n",
            "Valid:\tslot f1: 87.27569331158239\tintent accuracy: 98.85714285714286\tsemantic_error: 73.42857142857143\n",
            "Test:\tslot f1: 84.06816337571001\tintent accuracy: 96.42857142857143\tsemantic_error: 68.14285714285714\n",
            "EPOCH:  40  *******************************************************************\n",
            "Train:\tslot f1: 99.76744186046511\tintent accuracy: 100.0\tsemantic_error: 99.34270865178844\n",
            "Valid:\tslot f1: 86.92579505300354\tintent accuracy: 98.71428571428571\tsemantic_error: 71.28571428571429\n",
            "Test:\tslot f1: 84.14502164502164\tintent accuracy: 96.71428571428572\tsemantic_error: 68.14285714285714\n",
            "EPOCH:  41  *******************************************************************\n",
            "Train:\tslot f1: 99.21933577382791\tintent accuracy: 99.77071232039133\tsemantic_error: 97.76826658514216\n",
            "Valid:\tslot f1: 84.6340804752903\tintent accuracy: 97.0\tsemantic_error: 67.85714285714286\n",
            "Test:\tslot f1: 83.13641245972073\tintent accuracy: 96.0\tsemantic_error: 66.0\n",
            "EPOCH:  42  *******************************************************************\n",
            "Train:\tslot f1: 99.65563927478219\tintent accuracy: 100.0\tsemantic_error: 99.01406297768267\n",
            "Valid:\tslot f1: 86.17223580548765\tintent accuracy: 98.42857142857143\tsemantic_error: 70.57142857142857\n",
            "Test:\tslot f1: 83.88663967611336\tintent accuracy: 97.14285714285714\tsemantic_error: 67.42857142857143\n",
            "EPOCH:  43  *******************************************************************\n",
            "Train:\tslot f1: 99.7438916691198\tintent accuracy: 100.0\tsemantic_error: 99.28920819321308\n",
            "Valid:\tslot f1: 86.41304347826087\tintent accuracy: 98.28571428571429\tsemantic_error: 70.71428571428572\n",
            "Test:\tslot f1: 83.93194706994328\tintent accuracy: 97.14285714285714\tsemantic_error: 68.14285714285714\n",
            "EARLY BREAK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o15eK9npnOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "7ab78a25-5eaf-4015-955d-f02062f024d4"
      },
      "source": [
        "#Let's try to clear slate and reload maodel  .....\n",
        "import time\n",
        "tf.keras.backend.clear_session()\n",
        "if arg.dataset == 'atis':\n",
        "    test_batch = 893\n",
        "elif arg.dataset == 'snips':\n",
        "    test_batch = 700\n",
        "\n",
        "model = MyModel(len(in_vocab['vocab']), len(slot_vocab['vocab']), len(intent_vocab['vocab']), layer_size=arg.layer_size)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(-1), optimizer=opt, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, arg.model_path + \"/\" + arg.dataset + '/tf_ckpts', max_to_keep=3)\n",
        "ckpt.restore(manager.latest_checkpoint)\n",
        "\n",
        "data_processor_test = DataProcessor(os.path.join(full_test_path, arg.input_file), os.path.join(full_test_path, arg.slot_file), os.path.join(full_test_path, arg.intent_file), in_vocab, slot_vocab, intent_vocab)\n",
        "in_data, slot_labels, slot_weights, length, intent_labels,in_seq,_,_ = data_processor_test.get_batch(test_batch)\n",
        "data_processor_test.close()\n",
        "\n",
        "\n",
        "\n",
        "t = time.perf_counter()\n",
        "slots, intent = model(in_data, length, isTraining = False)\n",
        "elapsed = time.perf_counter() - t\n",
        "print(\"Milli seconds per query:\", (elapsed*1000)/float(100.0))\n",
        "\n",
        "pred_intents = []\n",
        "correct_intents = []\n",
        "slot_outputs = []\n",
        "correct_slots = []\n",
        "input_words = []\n",
        "\n",
        "for i in np.array(intent):\n",
        "    pred_intents.append(np.argmax(i))\n",
        "for i in intent_labels:\n",
        "    correct_intents.append(i)\n",
        "\n",
        "pred_slots = slots\n",
        "for p, t, i, l in zip(pred_slots, slot_labels, in_data, length):\n",
        "    p = np.argmax(p, 1)\n",
        "    tmp_pred = []\n",
        "    tmp_correct = []\n",
        "    tmp_input = []\n",
        "    for j in range(l):\n",
        "        tmp_pred.append(slot_vocab['rev'][p[j]])\n",
        "        tmp_correct.append(slot_vocab['rev'][t[j]])\n",
        "        tmp_input.append(in_vocab['rev'][i[j]])\n",
        "\n",
        "    slot_outputs.append(tmp_pred)\n",
        "    correct_slots.append(tmp_correct)\n",
        "    input_words.append(tmp_input)\n",
        "\n",
        "pred_intents = np.array(pred_intents)\n",
        "correct_intents = np.array(correct_intents)\n",
        "accuracy = (pred_intents==correct_intents)\n",
        "semantic_error = accuracy\n",
        "accuracy = accuracy.astype(float)\n",
        "accuracy = np.mean(accuracy)*100.0\n",
        "\n",
        "index = 0\n",
        "for t, p in zip(correct_slots, slot_outputs):\n",
        "    # Process Semantic Error\n",
        "    if len(t) != len(p):\n",
        "        raise ValueError('Error!!')\n",
        "\n",
        "    for j in range(len(t)):\n",
        "        if p[j] != t[j]:\n",
        "            semantic_error[index] = False\n",
        "            break\n",
        "    index += 1\n",
        "semantic_error = semantic_error.astype(float)\n",
        "semantic_error = np.mean(semantic_error)*100.0\n",
        "\n",
        "f1, precision, recall = computeF1Score(correct_slots, slot_outputs)\n",
        "print('slot f1: ' + str(f1) + '\\tintent accuracy: ' + str(accuracy) + '\\tsemantic_accuracy: ' + str(semantic_error))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0609 18:51:34.959261 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3af8d9bd8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:34.969637 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cab3d4a8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:34.975452 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb6008b8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:34.981341 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600ae8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:34.986872 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600f48> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:34.992088 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:34.999299 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600408> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:35.005201 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600d18> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:35.010444 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600c28> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:35.015820 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600318> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "W0609 18:51:35.020871 140413534459776 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600d68> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3af8d9bd8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cab3d4a8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb6008b8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600ae8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600f48> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600048> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600408> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600d18> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600c28> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600318> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7fb3cb600d68> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
            "Milli seconds per query: 17.843537730000207\n",
            "slot f1: 83.10010764262647\tintent accuracy: 97.42857142857143\tsemantic_accuracy: 66.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RSRiDmPlNeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}